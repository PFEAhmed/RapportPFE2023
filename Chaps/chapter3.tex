%\documentclass{report}
%\input{includePackages.tex}
%\begin{document}



\chapter{Sprint Two: Raspberry pi 4 and ESP32 Cam Integration for Logo Detection}
\section*{Introduction}
\section{Specification of requirements}
In this section, we introduce the different actors as well as the functional and non-functional requirements.
\subsection{actors identification }
\subsection{Description of functional requirements}
\begin{itemize}
\item The ESP32-CAM board should be able to capture a live stream of pictures or videos and make them available through its built-in server.
\item The raspberry pi should be able to connect to the server on the ESP32-CAM board and retrieve the images or videos.
\item The raspberry pi should be able to process the images to determine if a specific logo is present or not.
\item The raspberry pi should be able to process the images to determine if a specific logo is flipped on the x axis.
\item The raspberry pi should be able to process the images to determine if a specific logo is in the first or the second half of the product.
\item The raspberry pi should be able to provide some form of feedback or output indicating whether the logo is present and if it is flipped or not.
\end{itemize}
\subsection{Description of non-functional requirements}
The requirements do not stop at the functional level but tend towards requirements that contribute to better quality of the application. The most important ones are:
\begin{itemize}
\item \textbf{Reliability:} The system should be able to consistently capture and process images accurately.
\item \textbf{Performance:} The system should be able to process images quickly and without noticeable lag or delay.
\item \textbf{Security:} The system should have appropriate security measures in place to prevent unauthorized access to the servers and data.
\item \textbf{Scalability:} The system should be able to handle multiple simultaneous connections and requests from clients without compromising its performance.
\item \textbf{Maintainability:} The system should be easy to maintain and update, with clear and well-documented code and configuration.
\item \textbf{Compatibility:} The system should be compatible with a wide range of devices and platforms.
\item \textbf{Usability:} The system should be easy to use and understand for both technical and non-technical users.
\end{itemize}

\section{Modeling languages diagrams}
\subsection{SysMl}
\FloatBarrier
\begin{figure}[htbp]
    \centering
    \begin{tikzpicture}
        \node[draw, fill=white, minimum height=2cm, minimum width=2cm, line width=2pt] (ESP32-CAM) at (-4,0) {};
        \node[draw, fill=white, minimum height=2cm, minimum width=2cm, line width=2pt] (Raspberry_pi) at (-4,-5) {};
      %  \umlactor[x=-4, y=0, scale=2,draw=black, line width=2pt]{ESP32-CAM}
        %\umlactor[x=-4, y=-5, scale=2,draw=black, line width=2pt]{ESP32}
  \umlusecase[x=-2, y=4, width=3cm, name=server,fill=white,draw=black, line width=2pt]{\begin{tabular}{c}Create a server\\         \end{tabular}}
  \umlusecase[x=7, y=4, width=3cm, name=connect,fill=white,draw=black, line width=2pt]{\begin{tabular}{c}Connect to a wifi\\         \end{tabular}}
  \umlusecase[x=5, y=-1, width=3cm, name=connect2,fill=white,draw=black, line width=2pt]{\begin{tabular}{c}Connect to a wifi\\         \end{tabular}}
  \umlusecase[x=0, y=-2, width=3cm, name=connect_to_server,fill=white,draw=black, line width=2pt]{\begin{tabular}{c}Connect to the server \\         \end{tabular}}
        \umlusecase[x=0, y=2, width=3cm, name=footages,fill=white,draw=black, line width=2pt]{\begin{tabular}{c}Take live footages\\         \end{tabular}}
        \umlusecase[x=0, y=-4, width=3cm, name=predict,fill=white,draw=black, line width=2pt]{\begin{tabular}{c}Predict the state\\of the logo\\\end{tabular}}
        \umlusecase[x=5, y=3, width=3cm, name=extend1,fill=white,draw=black, line width=2pt]{\begin{tabular}{c}Take photos\end{tabular}} 
        \umlusecase[x=5, y=1, width=3cm, name=extend2,fill=white,draw=black, line width=2pt]{\begin{tabular}{c}Take vidoes\end{tabular}}  
        \umlusecase[x=4, y=-11, width=3cm, name=Present logo,fill=white,draw=black, line width=2pt]{\begin{tabular}{c}Present logo\end{tabular}} 
        \umlusecase[x=5, y=-4, width=3cm, name=Flipped on the x axis,fill=white,draw=black, line width=2pt]{\begin{tabular}{c}Logo flipped on \\ the x  axis\end{tabular}}  
   \umlusecase[x=5.5, y=-6, width=4.25cm, name=first,fill=white,draw=black, line width=2pt]{\begin{tabular}{c}Logo flipped on \\ the first half of the product\end{tabular}}  
  \umlusecase[x=5.5, y=-8, width=4.25cm, name=second,fill=white,draw=black, line width=2pt]{\begin{tabular}{c}Logo flipped on \\ the second half of the product\end{tabular}}  
        \umlusecase[x=5, y=-2.5, width=3cm, name=No logo,fill=white,draw=black, line width=2pt]{\begin{tabular}{c}No logo\end{tabular}}  
%\draw[->] (connect_to_server.west) -| node[pos=1, above] {<<secondary>>} ([xshift=-4mm]ESP32-CAM.east) |- (connect_to_server.east);


  \umlinclude{server}{connect}
 \umlinclude{connect_to_server}{predict}
 \umlinclude{connect2}{connect_to_server}

        \umlinherit{Present logo}{predict}
        \umlinherit{Flipped on the x axis}{predict}
        \umlinherit{No logo}{predict} 
        \umlinherit{first}{predict}
        \umlinherit{second}{predict}  
        \umlinherit{extend1}{footages}  
        \umlinherit{extend2}{footages} 

        \node[fit=(predict), inner ysep=4ex] {}; % increase height of predict use case
        \node[fit=(Flipped on the x axis), inner ysep=4ex]{};
        \node[fit=(first), inner xsep=8ex]{};
        \umlassoc{ESP32-CAM}{footages}
  \umlassoc{ESP32-CAM}{server}
\node[below] at (ESP32-CAM.south) {ESP32-CAM};
        \node[below] at (Raspberry_pi.south) {Raspberry pi};
        \umlassoc{Raspberry_pi}{predict}
    \end{tikzpicture}
    \caption{Use case Diagram for sprint version 1}
    \label{fig:usecase-sprint0}
\end{figure}



\FloatBarrier




\section{Project component}
\subsection{Hardware environment}
\subsubsection{ESP32-CAM}
\FloatBarrier
\begin{figure}[h]
         \centering
        \includegraphics[width=0.4\textwidth]{esp32cam}
   
        \caption{ESP32-CAM}
        \label{fig:esp32cam}
    \end{figure}
\FloatBarrier
\FloatBarrier
\begin{table}[h]
\centering
\begin{tabular}{|l|l|}
\hline
\textbf{Component} & \textbf{Specification} \\ \hline
WiFi+Bluetooth module & ESP-32S \\ \hline
Camera module & OV2640 2MP \\ \hline
SPI Flash & 4MB \\ \hline
RAM & Internal 512KB + External 4MB PSRAM \\ \hline
Onboard TF card slot & Supports up to 4G TF card for data storage \\ \hline
Wi-Fi & 802.11b/g/n/e/i \\ \hline
Operating voltage & 3.3/5 Vdc \\ \hline
Power consumption (Flash off) & 180mA@5V \\ \hline
Power consumption (Flash on and brightness max) & 310mA@5V \\ \hline
Power consumption (Modern-Sleep) & as low as 20mA@5V \\ \hline
Power consumption (Light-Sleep) & as low as 6.7mA@5V \\ \hline
Power consumption (Deep-Sleep) & as low as 6mA@5V \\ \hline
Operating temperature & -20 °C ~ 85 °C \\ \hline
Dimensions & 40.5mm x 27mm x 4.5mm \\ \hline
Flash light & LED built-in on board \\ \hline
\end{tabular}
\caption{ESP32-CAM characteristics \cite{HT}}
\label{table:esp32-cam-characteristics}
\end{table}
\FloatBarrier

\subsubsection{PC}
\FloatBarrier
\begin{figure}[h]
         \centering
        \includegraphics[width=0.4\textwidth]{lenovo-ideapad-gaming-3}
   
        \caption{lenovo ideapad gaming 3}
        \label{fig:lenovo-ideapad-gaming-3}
    \end{figure}
\FloatBarrier

\begin{table}[h]
\centering
\begin{tabular}{|l|l|}
\hline
\textbf{Component} & \textbf{Specification} \\ \hline
Processor & AMD Ryzen 7 4800H \\ \hline
Memory & 16 GB DDR4 RAM \\ \hline
Graphics & NVIDIA GeForce GTX 1650Ti (4GB GDDR6) \\ \hline
Storage & 512 GB SSD \\ \hline
Operating System & Windows 10 \\ \hline
\end{tabular}
\caption{Specifications of the PC}
\label{table:pc-specifications}
\end{table}

\subsection{Software environment }
\subsubsection{Software}
\begin{itemize}
  %\item Arduino IDE
%\FloatBarrier
%\begin{figure}[h]
   %      \centering
      %  \includegraphics[width=0.2\textwidth]{ArduinoIDELogo}
   
        %\caption{Arduino IDE Logo}
        %\label{fig:ArduinoIDELogo}
    %\end{figure}
%\FloatBarrier
%\subitem\textbf{Arduino IDE} is an official Arduino software application used for writing, compiling, and uploading code to Arduino microcontrollers. The IDE environment consists of two basic parts: Editor and Compiler and supports both C and C++ languages.\cite{MA18}

  \item Raspberry Pi Imager
\begin{figure}[h]
       \centering
        \includegraphics[width=0.5\textwidth]{raspberry-pi-imagerLogo}
   
        \caption{Raspberry pi imager logo}
        \label{fig:raspberry-pi-imagerLogo}
    \end{figure}
\FloatBarrier
\subitem\textbf{Raspberry Pi Imager}  is a free and open-source software application developed by the Raspberry Pi Foundation.\cite{RSND}
With Raspberry Pi Imager, users can easily choose to install a variety of os, like Raspbian, Ubuntu, Kali Linux, and more,  onto a microSD card that can be used to boot up your Raspberry Pi.
\subitem  It can be downloaded and installed on Windows, Mac, and Linux operating systems.\cite{RSND}
 \item PuTTY
\FloatBarrier
\begin{figure}[h]
       \centering
        \includegraphics[width=0.2\textwidth]{puttyLogo}
   
        \caption{puttyLogo}
        \label{fig:}
    \end{figure}
\FloatBarrier
\subitem\textbf{PuTTY} is a free and open-source terminal emulator, serial console, and network file transfer application. It was originally developed for Windows but is now available on many other operating systems.\cite{PYND}
\subitem PuTTY also supports many network protocols, such as Telnet, rlogin, SSH and raw TCP. It also includes additional features such as session management, SSH key generation, and support for local printing.\cite{PYND}
 \item VNC
\FloatBarrier
\begin{figure}[h]
       \centering
        \includegraphics[width=0.2\textwidth]{VNCLogo}
   
        \caption{VNCLogo}
        \label{fig:VNCLogo}
    \end{figure}
\FloatBarrier
\subitem\textbf{VNC } (Virtual Network Computing) is a thin-client system that allows users to remotely control and operate another computer or server over a network. It consists of two components: a server that runs on the remote computer, and a client that runs on the local computer.\cite{RVND}
\subitem  The server sends screen updates to the client, so the user can see and interact with the remote computer's desktop as if they were sitting right in front of it.\cite{RVND}
  \item Geany
\begin{figure}[h]
         \centering
        \includegraphics[width=0.2\textwidth]{Geanylogo}
   
        \caption{Geany logo}
        \label{fig:Geanylogo}
    \end{figure}
\FloatBarrier
\subitem\textbf{Geany} is a simple and lightweight text editor designed for programmers and developers. It provides features such as syntax highlighting for a wide range of programming languages, code folding, auto-indentation, and built-in support for various programming tools and compilers.\cite{GND}
  \item Google Colab
\begin{figure}[h]
         \centering
        \includegraphics[width=0.4\textwidth]{ColabLogo}
   
        \caption{Google colab logo}
        \label{fig: Google Colab logo}
    \end{figure}
\FloatBarrier
\subitem\textbf{Google Colab} (short for Collaboratory) is a cloud-based platform provided by Google that allows users to run and share Jupyter notebook files for data analysis, machine learning and deep learning tasks. .\cite{GRND}
\subitem It provides access to computing resources such as CPU, GPU,RAM, disk and TPU for free, allowing users to execute complex computational tasks without the need to use their local hardware..\cite{GRND}
\end{itemize}
\subsubsection{programming languages}
\begin{itemize}

\item C++
\FloatBarrier
\begin{figure}[h]
         \centering
        \includegraphics[width=0.2\textwidth]{c++Logo}
   
        \caption{C++ logo}
        \label{fig:c++Logo}
    \end{figure}
\FloatBarrier
\subitem\textbf{C++} is a programming language that is widely used in software development. It is a standardized, general-purpose, and object-oriented language, which means it can be used to create a variety of applications, including system software, device drivers, video games, and desktop applications.\cite{SD20}

\item Python
\FloatBarrier
\begin{figure}[h]
         \centering
        \includegraphics[width=0.2\textwidth]{PythonLogo}
   
        \caption{Python logo}
        \label{fig:PythonLogo}
    \end{figure}
\FloatBarrier
\subitem\textbf{Python} is a popular high-level programming languagethat supports object-oriented, functional, 
and imperative programming styles. scripting language, but can be compiled into computer-readable binary.\cite{SD20}


\end{itemize}

\subsection{Workflow}
\subsubsection{Setting up the rapsberry pi}
\begin{itemize}
\item{ setting up the OS }
\begin{itemize}

\item 

\begin{minipage}{0.5\textwidth}
download the Raspberry Pi Imager from the official Raspberry Pi website.
\end{minipage}
\hfill
\begin{minipage}{0.6\textwidth}
\hspace*{0.3in} \includegraphics[width=\textwidth]{1i}
\end{minipage}
\vspace{0.5in}

\item 
\begin{minipage}{0.5\textwidth}
choose the raspberry pi operating system (64-bit)
\end{minipage}
\hfill
\begin{minipage}{0.6\textwidth}
\includegraphics[width=\textwidth]{3i}
\end{minipage}
\vspace{0.5in}
\item 
\begin{minipage}{0.5\textwidth}
Configure the parameters of the operating system: set a hostname,enable SSH,set username and password,configure wireless lan and set local settings
\end{minipage}
\hfill
\begin{minipage}{0.6\textwidth}
\includegraphics[width=\textwidth]{8i}
\end{minipage}
\vspace{0.5in}
\item 
\begin{minipage}{0.5\textwidth}
Select the SD card you want to use for the installation.
\end{minipage}
\hfill
\begin{minipage}{0.6\textwidth}
\includegraphics[width=\textwidth]{5i}
\end{minipage}
\vspace{0.5in}
\item 
\begin{minipage}{0.5\textwidth}
Click on the "Write" button to start the installation process. This will take several minutes to complete.
\end{minipage}
\hfill
\begin{minipage}{0.6\textwidth}
\includegraphics[width=\textwidth]{9i}
\end{minipage}
\end{itemize}


\item{setting up the VNC}
\begin{itemize}
\item{Establishing connection with puttty}
\FloatBarrier
\begin{figure}[h]

       \centering

        \includegraphics[width=0.5\textwidth]{1p}
   
        \caption{putty interface}
        \label{fig:putty interface}

    \end{figure}

\FloatBarrier
\end{itemize}
\begin{itemize}
\item In the "Host Name (or IP address)" field, enter the IP address of your Raspberry Pi.
\item In the "Port" field, enter "22". This is the default SSH port for Raspberry Pi.
\item Under "Connection type", select "SSH".
\item Click the "Open" button to start the SSH connection.
\end{itemize}
\item{Updating the system}
\FloatBarrier
\begin{figure}[h]

       \centering

        \includegraphics[width=0.5\textwidth]{updatefile}
   
        \caption{Update.sh file}
        \label{fig:update.sh}

    \end{figure}

\FloatBarrier
I have created \textbf{update.sh} that contain these three commands:
\begin{itemize}
\item \texttt{sudo apt-get update}: This command updates the list of available software packages and their versions from the repositories defined in the package manager sources list.
\item \texttt{sudo apt-get upgrade}: This command upgrades the installed packages on the system to their latest versions.
\item \texttt{sudo reboot}: This command restarts the system after the update and upgrade processes have completed.
\end{itemize}
To execute the update.sh just run this command:
\begin{lstlisting}
sh update.sh
\end{lstlisting}
This table represent the total time taking by this command:
\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|}
        \hline
        \textbf{Metric} & \textbf{Value} \\
        \hline
        real & 9.631 s \\
        \hline
        user & 3.065 s \\
        \hline
        sys & 1.097 s \\
        \hline
    \end{tabular}
    \caption{Execution time of sh update.sh}
    \label{tab:time}
\end{table}

\item{Activating VNC server}\\
Enter this command:
\begin{lstlisting}
sudo raspi-config
\end{lstlisting}
\FloatBarrier
\begin{figure}[h]

       \centering

        \includegraphics[width=0.5\textwidth]{5v}
   
        \caption{Enable vnc menu}
        \label{fig:Enable vnc menu}

    \end{figure}
\FloatBarrier
Go to Interfacing options > vnc and click on “Select” While their, enable vnc
\item{Prepare working environment}\\
\FloatBarrier
\begin{figure}[h]

       \centering

        \includegraphics[width=0.5\textwidth]{prepareEnv}
   
        \caption{prepareEnv.sh file}
        \label{fig:prepareEnv.sh file}

    \end{figure}
\FloatBarrier
I have created \textbf{prepareEnv.sh} that execute the following:
\begin{itemize}
    \item Create a new directory named "project" using the "mkdir" command.
    \item Change the current working directory to the "project" directory using the "cd" command.
    \item Clone the "yolov5" repository from the GitHub account of "ultralytics" using the "git clone" command.
    \item Install the "virtualenv" package using the "sudo pip install" command, which creates a virtual environment in the "env" directory.
    \item Change the current working directory to the "yolov5" directory using the "cd" command.
    \item Activate the virtual environment created earlier using the "." command followed by the path to the "env/bin/activate" file.
    \item Install the Python packages listed in the "requirements.txt" file using the "pip install -r" command.
    \item Install  torch version 1.13.1 torchvision version 0.14.1 torchaudio version 0.13.1 packages using the "pip3 install" command because the the ones in "requirements.txt" file are not compatible with the current yolov5.
    \item Install the "gpiozero" package using the "pip install" command.
    \item Install the "RPi.GPIO" package using the "pip install" command.
    \item Install the "subprocess.run" package using the "pip install" command.
    \item Install the "time" package using the "pip install" command.
    \item Clone the "YoloV5LogoDetection" repository from the GitHub account of "AhmedOmrani10" using the "git clone" command.
\end{itemize}
To execute the prepareEnv.sh just run this command:
\begin{lstlisting}
sh prepareEnv.sh
\end{lstlisting}
This table represent the total time taking by the command:
\begin{table}[h]
    \centering
    \begin{tabular}{|c|c|}
        \hline
        \textbf{Metric} & \textbf{Value} \\
        \hline
        real & 18.759 m \\
        \hline
        user & 3.334 s \\
        \hline
        sys & 31.253 s \\
        \hline
    \end{tabular}
    \caption{Execution time of sh prepareEnv.sh}
    \label{tab:time}
\end{table}

\end{itemize}
\subsubsection{Deep learning pipeline}
\begin{itemize}
\item{Selecting the deep learning model: Why YOLOv5s?}//
Before delving into the reasons for choosing YOLOv5s, it is important to understand some of the key metrics used to evaluate object detection models. 
\begin{itemize}
\item Precision:
\begin{equation}
P = \frac{TP}{TP+FP}
\end{equation}
Precision, also known as positive predictive value, is a metric used in machine learning to evaluate the accuracy of a classification model. It is calculated as the ratio of true positives to the sum of true positives and false positives. When expressed as a probability, it represents the likelihood that a randomly selected instance classified as positive is actually a true positive. A perfect classifier with no false positives has a precision of 1.\cite{KGMM21}

\item Recall:

\begin{equation}
R = \frac{TP}{TP+FN}
\end{equation}
Recall, also known as sensitivity, is a performance metric used in machine learning that measures the proportion of positive instances that are correctly identified as positive by the model. When expressed as a probability, it represents the likelihood that a randomly selected true positive instance will be correctly classified as positive by the model. Unlike precision, which only takes into account instances predicted as positive by the model, recall considers all actual positive instances.\cite{KGMM21}

\item mAP:

\begin{equation}
mAP = \frac{1}{n} \sum_{k=1}^{N} AP_k
\end{equation}
mAP is a metric based on the area under precision-recall curve (PRC) that is preprocessed to eliminate zig-zag behavior (Padilla et al., 2021 [1]). Where $AP_k$ is the average precision (AP) of class $k$ and $n$ is the number of thresholds. The mAP values were calculated at $Z$ value threshold value for intersection over union (IoU) meaning, all the predicted bounding boxes that resulted in ratios of overlapping areas to the union areas with ground truth bounding greater than $Z$ were considered and the remaining were discarded.\cite{MG21}

\item IoU:
\begin{equation}
IoU(A,B) = \frac{A \cap B}{A \cup B}, \quad IoU(A,B) \in [0,1]
\end{equation}
Intersection over Union (IoU) is a commonly used method to evaluate object detection algorithms. It measures the overlap between the proposed bounding box and the ground truth bounding box by computing the ratio of their intersection over their union. If the resulting value is above a certain threshold, the proposed bounding box is considered a correct detection.\cite{MG21}
\end{itemize}
In Table~\ref{tab:yolov5_comparison} and the firgure \ref{fig:comparisation}, we compare the performance of different YOLOv5 models.
\FloatBarrier
\begin{figure}[h]

       \centering

        \includegraphics[width=0.7\textwidth]{comparisationYolov5}
   
        \caption{Comparison between yolov5 family and Efficientdet for the COCO dataset in term of speed and accuracy}
        \label{fig:comparisation}

    \end{figure}
\FloatBarrier
\FloatBarrier
\begin{table}[h!]
  \centering
  
  \begin{tabular}{|c|c|c|c|c|c|c|c|}
    \hline
    \textbf{Model} & \textbf{Size (pixels)} & \textbf{mAPval@50-95} & \textbf{mAPval@50} & \textbf{Speed CPU b1 (ms)} & \textbf{Speed V100 b1 (ms)} & \textbf{Speed V100 b32 (ms)} & \textbf{Params (M)} \\ \hline
    YOLOv5n & 640 & 28.0 & 45.7 & 45 & 6.3 & 0.6 & 1.9 \\ \hline
    YOLOv5s & 640 & 37.4 & 56.8 & 98 & 6.4 & 0.9 & 7.2 \\ \hline
    YOLOv5m & 640 & 45.4 & 64.1 & 224 & 8.2 & 1.7 & 21.2 \\ \hline
    YOLOv5l & 640 & 49.0 & 67.3 & 430 & 10.1 & 2.7 & 46.5 \\ \hline
    YOLOv5x & 640 & 50.7 & 68.9 & 766 & 12.1 & 4.8 & 86.7 \\ \hline
  \end{tabular}
\caption{Comparison of YOLOv5 Models \cite{U23}}
  \label{tab:yolov5_comparison}
\vspace{0.5cm}

\footnotesize All YOLOv5 checkpoints in the table are trained up to 300 epochs with default settings. The Nano and Small models use hyp.scratch-low.yaml hyps, while all other models use hyp.scratch-high.yaml. The mAPval values shown in the table are for single-model single-scale on the COCO val2017 dataset. To reproduce these results, one can run the command "python val.py --data coco.yaml --img 640 --conf 0.001 --iou 0.65".\cite{U23}

The speed measurements shown in the table are averaged over COCO val images using an AWS p3.2xlarge instance. The NMS times, which take about 1 ms per image, are not included in these measurements. To reproduce these results, one can run the command "python val.py --data coco.yaml --img 640 --task speed --batch 1".\cite{U23}

The TTA (Test Time Augmentation) Test Time Augmentation includes reflection and scale augmentations. To reproduce these results, one can run the command "python val.py --data coco.yaml --img 1536 --iou 0.7 --augment".\cite{U23}
\end{table}
\FloatBarrier

The \textbf{YOLOv5} model is a state-of-the-art object detection model that has gained popularity due to its high accuracy and speed. The YOLOv5 family includes several models such as YOLOv5n, YOLOv5s, YOLOv5m, YOLOv5l, and YOLOv5x, each with different sizes and performance characteristics. To determine the best model for our application of logo detection on a Raspberry Pi 4, we used this table \ref{tab:yolov5_comparison} to compare the YOLOv5 models using metrics such as mAPval@50-95, mAPval@50, speed on CPU and V100, number of parameters, and FLOPs.//

Firstly, let's consider the Yolov5n model, which has the smallest size(1.9 million params) and computational requirements in the Yolov5 family. While this model is suitable for low-resource devices, it sacrifices accuracy (mAPval50-95 = 28.0 and mAPval50 =  45.7) for speed ( CPU b1 = 45 ms  , Speed V100 b1 = 6.3 ms and Speed V100 b32 = 	0.6 ms), making it less suitable for complex object detection tasks.

Next, the Yolov5m model strikes a balance between accuracy(mAPval50-95 = 45.4 and mAPval50 =  64.1) and speed ( CPU b1 = 224 ms, Speed V100 b1 = 8.2 ms and Speed V100 b32 = 1.7 ms), making it a popular choice for most applications. However, it still requires significant computational power (21.2 million params), which may not be feasible for low-resource devices like the Raspberry Pi 4.

The Yolov5l and x models offer the highest accuracy (mAPval50-95 = 49.0 and mAPval50 =  67.3 and mAPval50-95 = 50.7 and mAPval50 =  68.9 ) but come with even greater computational requirements (46.5 and 86.7 million params). They are best suited for high-end GPUs or cloud computing platforms and are not ideal for the Raspberry Pi 4.

Finally, we come to Yolov5s, which is the best choice for the Raspberry Pi 4. It has a smaller size and computational requirements (7.2 million params) than the other models in the family, making it easier to deploy on low-resource devices. Additionally, Yolov5s achieves high accuracy (mAPval50-95 = 37.4 and mAPval50 =  56.8) while maintaining a fast inference speed ( CPU b1 = 98 ms, Speed V100 b1 = 6.4 ms and Speed V100 b32 = 0.9 ms), making it an excellent choice for object detection tasks that require real-time performance.

In summary, the Yolov5s model is the best choice for the Raspberry Pi 4 due to its small size, low computational requirements, and high accuracy. It strikes the perfect balance between speed and accuracy, making it ideal for most object detection tasks.


\item{Building our dataset}
\FloatBarrier
\begin{figure}[ht]
  \centering
  \begin{minipage}[b]{0.45\linewidth}
    \includegraphics[width=\linewidth]{normalDataset}
    \caption{Normal dataset}
    \label{fig:image1}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.45\linewidth}
    \includegraphics[width=\linewidth]{invertedDataset}
    \caption{Inverted dataset}
    \label{fig:image2}
  \end{minipage}
\end{figure}
\FloatBarrier

To train our Yolov5s model, we first gathered a dataset of 726 images containing logos. We split the dataset into two classes: Normal and Inverted. The Normal class \ref{fig:image1} contained 363 images of logos in their standard orientation, while the Inverted class \ref{fig:image2} contained 363 images of logos that had been rotated 180 degrees.

\item{Image labeling}
\FloatBarrier
\begin{figure}[ht]
  \centering
    \includegraphics[width=\linewidth]{labeling}
    \caption{Labeling an image}
    \label{fig:labeling}


\end{figure}
\FloatBarrier
I used Roboflow to perform the image labeling. Image labeling involves annotating the images with bounding boxes that define the location of the logos in each image. This step is essential for training an object detection model like Yolov5s.
After hours of scouring through an endless stream of images and yelling at my computer screen, I finally finished the task of labeling the images for our dataset. With every annotation made, I felt as if a weight had been lifted from my shoulders (and added to my mouse finger). The satisfaction of seeing all of our hard work come together was almost as great as the relief of knowing I won't have to do it again anytime soon. Now, with our dataset fully labeled and ready for training, it's time to sit back, relax, and let the computer do the heavy lifting.
\item{Image data augmentation}
\FloatBarrier
\begin{figure}
    \centering
    \includegraphics[width=0.5\textwidth]{augmentatedDataset}
    \caption{Augmented dataset}
    \label{fig:Augmented dataset}
\end{figure}
\FloatBarrier
For data augmentation, we used several techniques in Roboflow, including Hue, Saturation, Brightness, and Blur. Hue refers to the color of the image, and we applied random rotations between -11° and +11° to create variations in color. Saturation refers to the intensity of the colors, and we applied random variations between -14\% and +14\% to increase the diversity of the dataset. Brightness refers to the overall brightness of the image, and we applied random variations between 0\% and +36\% to simulate different lighting conditions. Finally, we applied a blur of up to 0.75 pixels to simulate blurring caused by motion or other factors.

After augmenting our dataset, we ended up with triple the number of images, which allowed us to train a more robust model.
\end{itemize}












%\input{biblio.tex}




%\end{document}